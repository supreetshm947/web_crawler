# ğŸ“š Dynamic RAG Chatbot with Web Crawling

An AI assistant that dynamically learns from **web pages** using **retrieval-augmented generation (RAG)**.  

---

## ğŸ› ï¸ Technologies Used
- **PipeCat** ğŸˆ â†’ Building Pipeline
- **Daily** ğŸ’¬ â†’ Chatroom
- **LangChain** ğŸ¦œğŸ”— â†’ Prompt chaining, retriever, and memory  
- **FAISS** ğŸª â†’ In-memory vector database for storing embeddings  
- **all-MiniLM-L6-v2  Embeddings** ğŸ¤– â†’ Text vectorization  
- **ChatCohere** ğŸ§  â†’ Language model for generating responses  
- **BeautifulSoup** ğŸœ â†’ Web scraping for learning new knowledge  
- **Python** ğŸ â†’ The foundation of our AI chatbot  

---
## Architecture

<img src="workflow.png" alt="grid"><br>

---

## ğŸ“¥ Setup

### 1ï¸âƒ£ Set up environment variables
Add config in .env (.env_example for reference)

### 2ï¸âƒ£ Setup Poetry Virtual Environment
```bash
poetry install
```

### 3ï¸âƒ£ Start the Embedding Server
```
docker compose up
```

### 4ï¸âƒ£ Run the rag_chatbot_server.py
```bash
py rag_chatbot_server.py
```

---

## Pipeline

- ```DailyTransport``` initializes the Daily Chat room (```transport```).
- Pipecat binds together the agentic Flow as pipeline
```
 pipeline = Pipeline([
        transport.input(),
        tma_in,
        lc,
        tma_out
    ])
```
- ```tma_in``` mantains User context and ```tma_out``` mantains LLM Response/Assistant context.
- ```lc``` encapsulates a Langchain Retrieval Chain as an object of ```LLMUserResponseAggregator``` customized as ```LangchainRAGProcessor``` to implement fuzzy logic matching for URL and initiating web crawling.
- Pipeline gets initiates with ```on_chat_message``` listener on ```transport``` and initiates the Pipecat pipeline.

